{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this project, I will use an Alternating Least Squares (ALS) algorithm with Spark APIs to predict the ratings for the movies in [MovieLens Datasets](https://grouplens.org/datasets/movielens/latest/)\n",
    "\n",
    "##  [Alternating Least Squares](https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E6%8E%A8%E8%8D%90/papers/Large-scale%20Parallel%20Collaborative%20Filtering%20the%20Netflix%20Prize.pdf)\n",
    "ALS is one of the low rank matrix approximation algorithms for collaborative filtering. ALS decomposes user-item matrix into two low rank matrixes: user matrix and item matrix. In collaborative filtering, users and products are described by a small set of latent factors that can be used to predict missing entries. And ALS algorithm learns these latent factors by matrix factorization\n",
    "\n",
    "\n",
    "## Data Sets\n",
    "I use [MovieLens Datasets](https://grouplens.org/datasets/movielens/latest/).\n",
    "This dataset (ml-latest.zip) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 27753444 ratings and 1108997 tag applications across 58098 movies. These data were created by 283228 users between January 09, 1995 and September 26, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 1 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files `genome-scores.csv`, `genome-tags.csv`, `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:25.418967Z",
     "start_time": "2020-10-27T19:06:23.864500Z"
    }
   },
   "outputs": [],
   "source": [
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "# from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import recommender\n",
    "from recommender.data_loading.spark_get_data import load_csv_to_spark_df, load_csv_to_spark_rdd\n",
    "from recommender.data_cleaning.spark_preprocessing import get_rating, data_split\n",
    "from recommender.modeling.spark_collaborative_filtering import als_gridsearch\n",
    "from recommender.modeling.spark_recommend import make_recommendation, make_recommendation_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:32.165819Z",
     "start_time": "2020-10-27T19:06:28.593578Z"
    }
   },
   "outputs": [],
   "source": [
    "# spark config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"movie recommendation\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
    "    .config(\"spark.driver.memory\", \"96g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.master\", \"local[12]\") \\\n",
    "    .getOrCreate()\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:43.198981Z",
     "start_time": "2020-10-27T19:06:35.015662Z"
    }
   },
   "outputs": [],
   "source": [
    "movies = load_csv_to_spark_df('../dataset/movies.csv', spark)\n",
    "ratings = load_csv_to_spark_df('../dataset/ratings.csv', spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:44.185061Z",
     "start_time": "2020-10-27T19:06:44.049398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:45.821462Z",
     "start_time": "2020-10-27T19:06:45.712751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload data\n",
    "We will use an RDD-based API from pyspark.mllib to predict the ratings, so let's reload \"ratings.csv\" using sc.textFile and then convert it to the form of (user, item, rating) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:52.007939Z",
     "start_time": "2020-10-27T19:06:48.777386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 307, 3.5), (1, 481, 3.5), (1, 1091, 1.5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "movie_rating = load_csv_to_spark_rdd('../dataset/ratings.csv', sc)\n",
    "\n",
    "# preprocess data -- only need [\"userId\", \"movieId\", \"rating\"]\n",
    "rating_data = get_rating(movie_rating)\n",
    "\n",
    "# check three rows\n",
    "rating_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Now we split the data into training/validation/testing sets using a 6/2/2 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:06:57.465157Z",
     "start_time": "2020-10-27T19:06:57.439910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[35] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation, test = data_split(rating_data, [6, 2, 2])\n",
    "\n",
    "# cache data\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ALS based approach for training model\n",
    "1. ALS model selection and evaluation\n",
    "2. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS model selection and evaluation\n",
    "With the ALS model, we can use a grid search to find the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:51:37.330019Z",
     "start_time": "2020-10-27T19:07:12.769361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 latent factors and regularization = 0.001: validation RMSE is 0.8790523112952408\n",
      "8 latent factors and regularization = 0.01: validation RMSE is 0.8526333272385692\n",
      "8 latent factors and regularization = 0.05: validation RMSE is 0.8224192070107165\n",
      "8 latent factors and regularization = 0.1: validation RMSE is 0.8230813541241517\n",
      "8 latent factors and regularization = 0.2: validation RMSE is 0.865981220900152\n",
      "10 latent factors and regularization = 0.001: validation RMSE is 0.891151967668972\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 0.8562651468256183\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 0.8190701557383728\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 0.8206398496275041\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 0.8658968041719375\n",
      "12 latent factors and regularization = 0.001: validation RMSE is 0.8983982396110236\n",
      "12 latent factors and regularization = 0.01: validation RMSE is 0.8607961248888077\n",
      "12 latent factors and regularization = 0.05: validation RMSE is 0.815595773977843\n",
      "12 latent factors and regularization = 0.1: validation RMSE is 0.8177207403881877\n",
      "12 latent factors and regularization = 0.2: validation RMSE is 0.8654522749637065\n",
      "14 latent factors and regularization = 0.001: validation RMSE is 0.903520160419625\n",
      "14 latent factors and regularization = 0.01: validation RMSE is 0.862654823135562\n",
      "14 latent factors and regularization = 0.05: validation RMSE is 0.8140122902659009\n",
      "14 latent factors and regularization = 0.1: validation RMSE is 0.8168413394296484\n",
      "14 latent factors and regularization = 0.2: validation RMSE is 0.8655022077098884\n",
      "16 latent factors and regularization = 0.001: validation RMSE is 0.9183730755279434\n",
      "16 latent factors and regularization = 0.01: validation RMSE is 0.8713838671999584\n",
      "16 latent factors and regularization = 0.05: validation RMSE is 0.8142884900967092\n",
      "16 latent factors and regularization = 0.1: validation RMSE is 0.8171982709582325\n",
      "16 latent factors and regularization = 0.2: validation RMSE is 0.8656837361609582\n",
      "18 latent factors and regularization = 0.001: validation RMSE is 0.9266749734888473\n",
      "18 latent factors and regularization = 0.01: validation RMSE is 0.8758700910537974\n",
      "18 latent factors and regularization = 0.05: validation RMSE is 0.8157550589625854\n",
      "18 latent factors and regularization = 0.1: validation RMSE is 0.8191799462689717\n",
      "18 latent factors and regularization = 0.2: validation RMSE is 0.8668821776700181\n",
      "20 latent factors and regularization = 0.001: validation RMSE is 0.930750698369542\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 0.8792353539228716\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 0.8153691770950987\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.818147128063305\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 0.8662696647985894\n",
      "\n",
      "The best model has 14 latent factors and regularization = 0.05\n"
     ]
    }
   ],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 10\n",
    "# ranks = [14]\n",
    "# reg_params = [0.05]\n",
    "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# grid search and select best model\n",
    "final_model = als_gridsearch(train, validation, num_iterations, reg_params, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:57:24.305487Z",
     "start_time": "2020-10-27T19:56:40.840314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 0.8141\n"
     ]
    }
   ],
   "source": [
    "# make prediction using test data\n",
    "test_data = test.map(lambda p: (p[0], p[1]))\n",
    "predictions = final_model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# get the rating result\n",
    "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "# get the RMSE\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "error = math.sqrt(MSE)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make movie recommendation\n",
    "Define a function to make top 10 recommendations to a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:57:34.911628Z",
     "start_time": "2020-10-27T19:57:29.928082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 1:\n",
      "1: Eve and the Fire Horse (2005)\n",
      "2: Crime Wave (1985)\n",
      "3: Boogie-Doodle (1948)\n",
      "4: Kaaka Muttai (2015)\n",
      "5: Morgan Murphy: Irish Goodbye (2014)\n",
      "6: The Zohar Secret (2015)\n",
      "7: Who Killed Chea Vichea? (2010)\n",
      "8: Final Cut: Ladies and Gentlemen (2012)\n",
      "9: NOFX Backstage Passport 2\n",
      "10: Heroes (2008)\n"
     ]
    }
   ],
   "source": [
    "# get recommends\n",
    "recommends = make_recommendation(\n",
    "    model = final_model, \n",
    "    ratings_data = rating_data, \n",
    "    df_movies = movies, \n",
    "    user_id = 1, \n",
    "    n_recommendations = 10, \n",
    "    spark_context = sc)\n",
    "\n",
    "print('Recommendations for User {}:'.format(1))\n",
    "for i, title in enumerate(recommends):\n",
    "    print('{0}: {1}'.format(i+1, title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make movie recommendation to a new user\n",
    "We need to define a function that takes new user's movie rating and output top 10 recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T19:59:40.419967Z",
     "start_time": "2020-10-27T19:57:40.349922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Iron Man:\n",
      "1: Scarlet Dove, The (Tulipunainen kyyhkynen) (1961)\n",
      "2: Pearl Jam: Immagine in Cornice - Live in Italy 2006 (2007)\n",
      "3: Presumed Guilty (Presunto culpable) (2008)\n",
      "4: The Veil of Twilight (2014)\n",
      "5: O Pátio das Cantigas (1942)\n",
      "6: Hunterrr (2015)\n",
      "7: Margaret Cho: PsyCHO (2015)\n",
      "8: Heroes Above All (2017)\n",
      "9: The Magnificent Scoundrels (1991)\n",
      "10: Whitney Cummings: Money Shot (2010)\n"
     ]
    }
   ],
   "source": [
    "# my favorite movies\n",
    "my_favorite_movies = ['Iron Man', 'Jumanji', 'Transformers', 'Independence Day']\n",
    "\n",
    "# get recommends\n",
    "recommends = make_recommendation_new(\n",
    "    best_model_params = {'iterations': 10, 'rank': 14, 'lambda_': 0.05}, \n",
    "    ratings_data=rating_data, \n",
    "    df_movies=movies, \n",
    "    fav_movie_list=my_favorite_movies, \n",
    "    n_recommendations=10, \n",
    "    spark_context=sc)\n",
    "\n",
    "print('Recommendations for {}:'.format(my_favorite_movies[0]))\n",
    "for i, title in enumerate(recommends):\n",
    "    print('{0}: {1}'.format(i+1, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
